{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc46e350-d998-49ff-afbe-46c51956d675",
   "metadata": {},
   "source": [
    "# Crie um aplicativo LLM simples com LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3bfbd-50c7-4936-9fa3-6fe7465ed4b8",
   "metadata": {},
   "source": [
    "Para instalar o LangChain, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "724e1b13-be46-4efe-b42c-cd9edfc00cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (0.2.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b6b9a-ce28-49c3-beb2-83a8375df909",
   "metadata": {},
   "source": [
    "##### LangSmith\n",
    "\n",
    "Muitas das aplicações que você constrói com LangChain conterão múltiplas etapas com várias invocações de chamadas de LLM. À medida que essas aplicações se tornam mais complexas, torna-se crucial poder inspecionar o que exatamente está acontecendo dentro da sua cadeia ou agente. A melhor maneira de fazer isso é com LangSmith.\n",
    "\n",
    "Após se inscrever no link acima, certifique-se de configurar suas variáveis de ambiente para começar a registrar rastreamentos:\n",
    "\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"...\"\n",
    "\n",
    "Ou:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63af540-b809-48c7-818b-2fa8347d5b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5609e-1244-4c3c-8020-6d77118fa42c",
   "metadata": {},
   "source": [
    "##### Usando Modelos de Linguagem\n",
    "\n",
    "Primeiro, vamos aprender como usar um modelo de linguagem por si só. LangChain suporta diversos modelos de linguagem que podem ser usados de forma intercambiável\n",
    "selecione abaixo o que você deseja utilizar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ddcb44-b99d-4d20-bede-684bcb93c8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-mistralai in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-mistralai) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse<1,>=0.3.1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-mistralai) (0.4.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-mistralai) (0.2.5)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15.1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-mistralai) (0.19.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3,>=0.2.0->langchain-mistralai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3,>=0.2.0->langchain-mistralai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3,>=0.2.0->langchain-mistralai) (0.1.77)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3,>=0.2.0->langchain-mistralai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3,>=0.2.0->langchain-mistralai) (2.7.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langchain-core<0.3,>=0.2.0->langchain-mistralai) (8.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.23.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.0->langchain-mistralai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.0->langchain-mistralai) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.0->langchain-mistralai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.0->langchain-mistralai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\joao.calmeida\\documents\\langchain\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f571fb-55e1-4f9e-8c89-fcbb0632edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f57a1-396d-41dd-81ad-76f67951b424",
   "metadata": {},
   "source": [
    "Vamos primeiro usar o modelo diretamente. ChatModels são instâncias de \"Runnables\" do LangChain, o que significa que eles expõem uma interface padrão para interagir com eles. Para simplesmente chamar o modelo, podemos passar uma lista de mensagens para o método .invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a24431-5350-4ea2-9737-05f9c00ca8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! In Portuguese, this is \"Olá!\" Please note that, like in English, the exclamation mark is used to convey enthusiasm or excitement.', response_metadata={'token_usage': {'prompt_tokens': 17, 'total_tokens': 50, 'completion_tokens': 33}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-d022b7ff-5534-4dd6-86df-1a41159da4c8-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into portuguese\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ad297-2b84-4fe3-bc41-8a4cae3f6708",
   "metadata": {},
   "source": [
    "\n",
    "Se tivermos habilitado o LangSmith, podemos ver que esta execução é registrada no LangSmith e podemos ver o rastreamento no LangSmith."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a6d9c-eeaa-4b51-945c-585896a58242",
   "metadata": {},
   "source": [
    "##### OutputParsers\n",
    "\n",
    "Observe que a resposta do modelo é um AIMessage. Isso contém uma resposta em forma de string junto com outros metadados sobre a resposta. Muitas vezes, podemos querer trabalhar apenas com a resposta em forma de string. Podemos extrair apenas esta resposta utilizando um parser de saída simples.\n",
    "\n",
    "Primeiro, importamos o parser de saída simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "567c1eff-bacb-4151-a23d-3f23b60b81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a43629-93b9-4454-8150-03c701676c1c",
   "metadata": {},
   "source": [
    "Uma forma de usá-lo é usá-lo sozinho. Por exemplo, poderíamos salvar o resultado da chamada do modelo de linguagem e então passá-lo para o parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da04b697-562e-4b46-8983-0fb83423ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ed45cf8-c787-4e15-8773-a2765c06bca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! In Portuguese, this is typically translated as \"Olá!\" Please note that, like in English, there are many ways to greet someone in Portuguese, and the choice often depends on the context, formality, and regional variations of the language.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9433b3ef-ce20-4260-b0dc-83b672a312c6",
   "metadata": {},
   "source": [
    "Mais comumente, podemos \"encadear\" o modelo com este parser de saída. Isso significa que este parser de saída será chamado toda vez nesta cadeia. Esta cadeia assume o tipo de entrada do modelo de linguagem (string ou lista de mensagens) e retorna o tipo de saída do parser de saída (string).\n",
    "\n",
    "Podemos criar facilmente a cadeia usando o operador |. O operador | é usado no LangChain para combinar dois elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a751952f-1ea4-4f5e-91c0-c5a7e84c7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b4afa15-12e7-4ea8-82da-40fe9e2238b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! In Portuguese, this is typically translated as \"Olá!\" Please note that, like in English, there are many ways to greet someone in Portuguese, and the choice often depends on the context and the relationship between the people conversing. For example, \"Oi\" is another common, informal way to say \"hi\" in Portuguese.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe983e-47f2-494e-a2bb-40aac22b2f74",
   "metadata": {},
   "source": [
    "##### Templates de Prompt\n",
    "\n",
    "Atualmente, estamos passando uma lista de mensagens diretamente no modelo de linguagem. De onde vem essa lista de mensagens? Normalmente, ela é construída a partir de uma combinação de entrada do usuário e lógica de aplicação. Essa lógica de aplicação geralmente pega a entrada bruta do usuário e a transforma em uma lista de mensagens pronta para passar ao modelo de linguagem. Transformações comuns incluem adicionar uma mensagem de sistema ou formatar um template com a entrada do usuário.\n",
    "\n",
    "PromptTemplates são um conceito no LangChain projetado para auxiliar nessa transformação. Eles recebem a entrada bruta do usuário e retornam dados (um prompt) que estão prontos para serem passados para um modelo de linguagem.\n",
    "\n",
    "Vamos criar um PromptTemplate aqui. Ele receberá duas variáveis do usuário:\n",
    "\n",
    "- language: O idioma para o qual traduzir o texto\n",
    "- text: O texto a ser traduzido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7b41a9f-92d4-4876-bd39-a9667daa36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961274fc-3fd4-4db8-8128-8c64700d1139",
   "metadata": {},
   "source": [
    "Primeiro, vamos criar uma string que formataremos para ser a mensagem do sistema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab389595-a2d8-4d76-b5e2-ccf4453d2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8d99a-ba02-436d-9fdd-4725f9eb7f33",
   "metadata": {},
   "source": [
    "A seguir, podemos criar o PromptTemplate. Este será uma combinação do system_template, bem como um modelo mais simples para onde colocar o texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6acdb147-6ec3-4b53-9a8e-f1341af5bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d5819-53f2-47ff-bca7-8dc6d82ea929",
   "metadata": {},
   "source": [
    "A entrada para este modelo de prompt é um dicionário. Podemos brincar com este modelo de prompt por si só para ver o que ele faz por si mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c4d6070-bc47-435e-a38e-360752188ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into portuguese:'), HumanMessage(content='hi')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"portuguese\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff81d60-a390-4ca1-a967-015680b54da3",
   "metadata": {},
   "source": [
    "Podemos ver que ele retorna um ChatPromptValue que consiste de dois mensagens. Se quisermos acessar as mensagens diretamente, fazemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f19f80a-ad64-45a7-8871-12b5fb944ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into portuguese:'),\n",
       " HumanMessage(content='hi')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1ac7b-8c1a-4b6a-8304-c97cc072b9cf",
   "metadata": {},
   "source": [
    "##### Encadeando componentes com LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be1a1b-6402-4685-8c42-bbce93cfc688",
   "metadata": {},
   "source": [
    "Agora podemos combinar isso com o modelo e o analisador de saída mencionados acima usando o operador pipe (|):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2a86965-0d65-42a1-a351-ebf7f8dd4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76bcd492-e305-4644-b371-2f4efe22e881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! The Portuguese translation for \"hi\" is \"olá\". So, you can say \"olá\" to greet someone in Portuguese.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"portuguese\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb37d9e-4436-4ba8-bb86-bb75eb43d8db",
   "metadata": {},
   "source": [
    "Este é um exemplo simples de como usar a Linguagem de Expressão LangChain (LCEL) para encadear módulos LangChain. Existem várias vantagens neste método, incluindo otimização de streaming e suporte a rastreamento.\n",
    "\n",
    "Se observarmos o rastreamento do LangSmith, podemos ver que todos os três componentes aparecem no rastreamento do LangSmith."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
